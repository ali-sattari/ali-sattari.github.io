<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Aggregating SLIs - Ali's Blog</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Aggregating SLIs"><meta itemprop=description content="With great number of SLIs come great responsibility aggregation issues. While aggregation provides more readability in overviews, it also inadvertently hides nuances and details. Our aim should be to propose a sensible aggregation method that ensures we extract the most valuable insights, with a promise to review it often in order to keep it fit.
When do you need to aggregate? Leaders managing large organisations, which often includes many services and lots of SLIs, usually ask for overview dashboards and reports."><meta itemprop=datePublished content="2024-08-28T12:13:14+00:00"><meta itemprop=dateModified content="2024-08-28T12:13:14+00:00"><meta itemprop=wordCount content="1133"><meta itemprop=keywords content="sre,sli,"><meta property="og:title" content="Aggregating SLIs"><meta property="og:description" content="With great number of SLIs come great responsibility aggregation issues. While aggregation provides more readability in overviews, it also inadvertently hides nuances and details. Our aim should be to propose a sensible aggregation method that ensures we extract the most valuable insights, with a promise to review it often in order to keep it fit.
When do you need to aggregate? Leaders managing large organisations, which often includes many services and lots of SLIs, usually ask for overview dashboards and reports."><meta property="og:type" content="article"><meta property="og:url" content="https://ali.sattari.me/posts/2024/aggregating-slis/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-28T12:13:14+00:00"><meta property="article:modified_time" content="2024-08-28T12:13:14+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Aggregating SLIs"><meta name=twitter:description content="With great number of SLIs come great responsibility aggregation issues. While aggregation provides more readability in overviews, it also inadvertently hides nuances and details. Our aim should be to propose a sensible aggregation method that ensures we extract the most valuable insights, with a promise to review it often in order to keep it fit.
When do you need to aggregate? Leaders managing large organisations, which often includes many services and lots of SLIs, usually ask for overview dashboards and reports."><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://ali.sattari.me/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://ali.sattari.me/css/main.css><link rel=stylesheet type=text/css href=https://ali.sattari.me/css/custom.css><link id=dark-scheme rel=stylesheet type=text/css href=https://ali.sattari.me/css/dark.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script>
<script src=https://ali.sattari.me/js/main.js></script></head><body><div class="container wrapper"><div class=header><h1 class=site-title><a href=https://ali.sattari.me/>Ali's Blog</a></h1><div class=site-description><p>Musings about technology, books and skepticism!</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/ali-sattari title=Github><i data-feather=github></i></a></li><li><a href=https://twitter.com/ali_sattari title=Twitter><i data-feather=twitter></i></a></li><li><a href=https://hardcover.app/@ali.sattari title=Hardcover><i data-feather=book-open></i></a></li><li><a href=https://www.linkedin.com/in/alisattari/ title=LinkedIn><i data-feather=linkedin></i></a></li><li><a href=/index.xml title=RSS><i data-feather=rss></i></a></li></ul></nav><span class=scheme-toggle><a href=# id=scheme-toggle></a></div><nav class=nav><ul class=flat><li><a href=/about>About</a></li><li><a href=/posts>All posts</a></li><li><a href=/tags>Tags</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>28</span>
<span class=rest>Aug 2024</span></div></div><div class=matter><h1 class=title>Aggregating SLIs</h1></div></div><div class=markdown><p>With great number of SLIs come great <del>responsibility</del> aggregation issues. While aggregation provides more readability in overviews, it also inadvertently hides nuances and details. Our aim should be to propose a sensible aggregation method that ensures we extract the most valuable insights, with a promise to review it often in order to keep it fit.</p><h2 id=when-do-you-need-to-aggregate>When do you need to aggregate?</h2><p>Leaders managing large organisations, which often includes many services and lots of SLIs, usually ask for overview dashboards and reports. Dashboards can give a sense of how systems are doing at a glance, reports can show how systems are doing overtime. Is some service (as a whole) having subpar reliability month over month? Are all indicators green while we are getting public complaints over social media? Answering these question with some rough confidence requires single (or very few) numbers, not all the detailed SLIs of the underlying services. To get to such overview we might need to aggregate SLIs per service, per product or sometimes at organisation level. The leadership ask are valid concerns with high level aims of resource allocation and planning, how we respond to that ask can make a lot of difference in what view we provide.</p><h2 id=what-are-some-aggregation-options-for-slis>What are some aggregation options for SLIs?</h2><p>This is a non-exhaustive list to show different ways of aggregating indicators to get a single number. There is no one correct way of aggregation in each case, like any form of aggregation we lose some signal in the process, and thus we need to find the method that keeps the most amount of signal relevant to us per case while keeping it simple.</p><p>Remember that SLIs are indicators, and as such they are already result of some formula for aggregation, often in form of ratios. At the same time they are far simpler than <a href=https://link.springer.com/referenceworkentry/10.1007/978-3-642-04898-2_15>composite indicators</a>, where many indicators are combined to form a new index, such as GDP or CPI. So they can‚Äôt be treated just like mere numbers, but they are much easier to deal with than their more complex cousins.</p><h3 id=summing-events>Summing events</h3><p>This means taking each data point (e.g. HTTP requests), and summing them for numerator (successful requests) and denominator (<a href=https://blog.alexewerlof.com/p/valid-vs-total>valid requests</a>). This gives more weight to individual events (e.g. each request) than each different SLI. In general this is only advised if different SLIs have the same base rate, so one SLI with higher traffic won&rsquo;t overshadow a lower-traffic one. If the scale of SLIs being aggregated varies widely (e.g. one has 10rps and another 100krps) you better use other methods, the alternative is to <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalise</a> the numbers.</p><blockquote><p>üí° One could argue if some SLIs can be aggregated in this way, aren‚Äôt they basically just one SLI to begin with? while this is theoretically correct, in practice these SLIs might fall into boundaries of different teams or services, so it could be beneficial to have them separate, and aggregate them like this, instead of sharing one SLI across team and diluting the ownership.</p></blockquote><h3 id=weighted-average>Weighted average</h3><p>This is about averaging the percentages, first simply by assuming equal weight for all. Equal weights would put more emphasis on each defined SLI rather than each event. Calculation is done by summing each indicator (percentage) and dividing by count of indicators. A more sophisticated approach is needed if SLIs differ widely in their impact, for that we assign weights to individual SLIs based on their impact, and calculate a weighted average.</p><blockquote><p>üí° An obvious shortcoming of this method is what statisticians call ‚Äúcompensability among indicators‚Äù, meaning that with averages higher indicators can compensate for lower ones and hiding flaws. Geometric average is what is often used as an easy remedy to prevent compensability, but I felt it is too complex for SLIs to include here.</p></blockquote><h3 id=percentiles>Percentiles</h3><p>Instead of averages, use percentiles (e.g., p50, p95) to account for potential outliers that could skew the results. This makes more sense for visualisations such as <a href=https://en.wikipedia.org/wiki/Box_plot>box plots</a> to show the range of values in a population that can also be compared with relative ease.</p><h3 id=count-of-slo-compliance>Count of SLO Compliance</h3><p>Count the number of services meeting their SLO targets to assess the overall reliability of the organisation, simple shown as <code>{count of compliant SLOs} / {total SLOs}</code> figure over a table, ideally with a simple <code>‚Üò/-/‚Üó</code>¬†to show change over past period. This is what Google also suggests in <a href=https://sre.google/workbook/implementing-slos/#slo-compliance-report>their SRE workbook</a>.</p><h2 id=start-simple-iterate-regularly>Start simple, Iterate regularly</h2><p>Start simple and iterate regularly to keep it up to date with reality. Your rate of iterating should match rate of change in your SLIs or the needs of the audience. Once or twice a year is often enough for such entities with low rate of change.</p><p>On each iteration you should look at two broad areas: your SLIs and your audience. You looked at your SLIs on the first run and decided upon a categorisation (e.g. per service) and an aggregation method (e.g. equally weighted average). Are those choices still valid? or has the reality changed and now some of the SLIs have different scale of traffic? or part of the bigger services is chipped away into new services? Next area is the audience and more importantly their needs, has the audience changed? was it initially just for use of CTO but now all VPs and EMs rely on the aggregate for different use-case? Did it start as a steering indicator for non-functional vs feature development, but now it is tied to annual bonuses? Reevaluating the way the aggregated figures are being used can inform decision on aggregation method.</p><blockquote><p>üí° One important signal that your aggregated figure is in need of an update is when a clear discrepancy is observed. This can show as indicator showing all systems green while there is a noticeable and damaging negative impact on services, or the converse.</p></blockquote><h2 id=what-about-a-target-slo-for-now-aggregated-slis>What about a target (SLO) for now aggregated SLIs?</h2><p>SLIs are useful indicators on their own<sup>[citation needed]</sup>, specially if we look at their trend over time like month over month, as such there is no immediate need for a target when we aggregate SLIs into one indicator. Many times we might want to even resist the urge to set a target for such aggregated SLI to avoid the <a href=https://en.wikipedia.org/wiki/Goodhart%27s_law>Goodhart‚Äôs trap</a>. But if we absolutely must, the simpler way is to set a new target for the aggregate SLI, using historical data and business needs as input. A more complicated approach can be calculating a composite SLO, beautifully described <a href=https://alexewerlof.medium.com/calculating-composite-sla-d855eaf2c655>here</a> in details. This approach makes more sense for service level aggregate SLIs, than for product or org level ones.</p><h2 id=resources>Resources</h2><ul><li><a href=https://www.coursera.org/lecture/site-reliability-engineering-slos/managing-complexity-with-aggregation-pLdiv>Managing complexity with aggregation</a></li><li><a href=https://medium.com/@asuffield/defining-an-slo-6302f60b218a#e3be>Defining an SLO > Aggregating SLOs</a></li><li><a href=https://www.robertoreif.com/blog/2018/1/7/why-you-should-be-careful-when-averaging-percentages>Why you should be careful when averaging percentages</a></li><li><a href=https://weallcount.com/2020/11/02/yes-you-can-average-averages/>Yes! You CAN Average Averages</a></li><li><a href=https://www.istat.it/it/files/2013/12/Rivista2013_Mazziotta_Pareto.pdf>Methods For Constructing Composite Indices: One For All Or All For One? (PDF)</a></li><li><a href=https://blog.alexewerlof.com/p/composite-slo>Calculating a composite SLO</a></li></ul></div><div class=tags><ul class=flat><li><a href=/tags/sre>sre</a></li><li><a href=/tags/sli>sli</a></li></ul></div></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-1ZG9PT72LY"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1ZG9PT72LY")</script><div class="footer wrapper"><nav class=nav><div>2024 All contents under <a href=https://www.gnu.org/licenses/fdl-1.3.html>GNU FDL</a> | <a href=https://github.com/knadh/hugo-ink>Ink</a> theme on <a href=https://gohugo.io>Hugo</a></div></nav></div><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-101616403-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script>
<script>feather.replace()</script></body></html>